

---

## ⚠️ 필수 설정: inotify limit 증가 (LM Studio 페이지 캐시 작동 조건)

**이 설정 없으면 페이지 캐시가 작동하지 않아 매번 HDD에서 느리게 로드됨!**

### 문제 현상
- LM Studio에서 모델 로드할 때마다 매번 느림
- 두 번째 로드도 첫 번째와 똑같이 느림
- 페이지 캐시(buff/cache)가 증가하지 않음

### 원인
Linux 기본 `inotify.max_user_watches` 값(65536)이 너무 낮음
→ LM Studio가 파일 감시 실패 → 캐시 우회 방식으로 읽음

### 해결 (일회성)
```bash
sudo sysctl fs.inotify.max_user_watches=524288
sudo sysctl fs.inotify.max_user_instances=1024
```

### 해결 (영구 설정) ✅
```bash
sudo tee /etc/sysctl.d/99-inotify.conf << 'EOF'
# LM Studio 페이지 캐시 정상 작동을 위한 설정
fs.inotify.max_user_watches = 524288
fs.inotify.max_user_instances = 1024
EOF
```

### 설정값 비교

| inotify.max_user_watches | 결과 |
|--------------------------|------|
| 65536 (기본값) | ❌ 캐시 안 됨, 매번 느림 |
| 524288 (권장) | ✅ 자동 캐시, 두 번째부터 빠름 |

### 테스트 결과 (2025-01-23)
- 65536: 59GB 모델 로드 → 매번 HDD 속도 (수 분)
- 524288: 59GB 모델 로드 → 첫 번째만 느림, 두 번째부터 RAM 속도 (수 초)

### 메모리 사용량
- 각 watch당 ~1KB 커널 메모리
- 524288 설정 시 최대 ~512MB (실제 사용량은 훨씬 적음)
- 현재 시스템: 265개만 사용 중 → 충분

---

✅ 이 버전은 네 목적에 100% 맞음

bind mount라서 off 까먹고 꺼도
✅ 재부팅하면 mount가 풀려서 “아무 일 없었던 것처럼 HDD로 정상복귀”

off는 이제 선택 없이
✅ 모든 mount 자동 해제 + RAM 복사본 전체 삭제 + tmpfs도 가능하면 umount



✅ 사용법 (너가 원하는 “초간단”)
✅ ON (기본 디폴트)
python3 hdd_to_ramdisk.py

✅ OFF (전부 자동 정리 + 자동 삭제)
python3 hdd_to_ramdisk.py off

✅ 상태 보기
python3 hdd_to_ramdisk.py status






python hdd_to_ramdisk.py 👉 기본은 ON (모델 선택 → RAMDisk 복사 → bind mount)

python hdd_to_ramdisk.py off 👉 전체 자동 원복 + RAM 복사본 전부 삭제 + RAMDisk 언마운트까지(가능하면)
→ “완전 없었던 일처럼” 돌아가기

그리고 업그레이드 포함:

✅ 남은 RAMDisk 용량 체크해서 부족하면 경고/중단

✅ mount/umount busy(모델 사용중)일 때 안내

✅ 상태 확인(status)

✅ OFF는 선택 없이 전부 자동 처리

아래가 그 업그레이드 완성본 프로토타입이야.

---

## 왜 tmpfs(RAMDisk)를 쓰는가? - 페이지 캐시 우회 문제

### 문제: 모델 파일을 읽었는데 페이지 캐시가 안 늘어남
"페이지 캐시를 우회해서 읽고 있거나(= 캐시가 안 쌓임) 읽자마자 바로 축출되는" 케이스

### 캐시가 안 늘어나는 대표 원인

1. **O_DIRECT로 열고 있음**
   - GDS(cuFile)·일부 로더/툴은 파일을 O_DIRECT로 열어서 페이지 캐시를 건너뜀
   - 컨테이너/서빙 프레임워크가 내부에서 이 플래그를 쓸 수 있음

2. **컨테이너/CGROUP 메모리 제한**
   - cgroup v2에선 페이지 캐시도 메모리 제한에 포함
   - 제한이 낮으면 캐시가 못 늘어남

3. **애플리케이션이 읽은 뒤 fadvise로 버림**
   - 어떤 로더는 읽고 나서 POSIX_FADV_DONTNEED로 캐시를 즉시 비우라고 힌트를 줌

4. **다른 작업 때문에 즉시 축출**
   - 여유 RAM이 빡빡하거나, I/O가 섞여 방금 적재한 캐시가 곧바로 밀려남

5. **원시 블록 디바이스를 직접 읽음**
   - /dev/sdX 같은 블록디바이스를 파일시스템 없이 읽으면 캐시 증가가 안 보임

### 진단 방법 (5분 점검)

```bash
# 1) 메모리 상황
free -h
grep -E 'MemTotal|MemAvailable|Cached|Buffers' /proc/meminfo

# 2) 사용 중인 마운트/옵션
mount | grep -E '/mnt|/data|/your_mountpoint'

# 3) GDS(쿠파일) 우회 여부 확인
echo $CUFILE_ENV_FORCE_COMPAT_MODE        # 1이면 GDS 비활성/버퍼드 경로 강제
echo $CUFILE_ENV_PATH                     # cuFile 설정 파일 경로

# 4) 실제 열기 플래그 보기 (strace로 감싸서)
strace -f -e trace=openat your_loader args 2>&1 | grep -E 'openat(.*O_DIRECT|O_DSYNC)'
```

`openat(… O_DIRECT …)` 가 보이면 **캐시 우회 중**입니다.

### 해결 방법

#### A. RAM에 올려두는(워밍업) 표준 방법
```bash
# 캐시 워밍업: 파일을 한 번 통째로 읽음
time cat /path/to/model.bin > /dev/null

# 두 번째는 RAM에서 나와야 훨씬 빨라짐
time cat /path/to/model.bin > /dev/null
```
이때 Cached 값이 늘어야 정상. 안 늘면 위 원인들을 의심.

#### B. tmpfs에 복사 (← 이 스크립트가 하는 방식) ✅
```bash
sudo mkdir -p /mnt/ram
sudo mount -t tmpfs -o size=80G tmpfs /mnt/ram
cp /data/model.bin /mnt/ram/
```
**tmpfs는 곧바로 RAM을 쓰므로 페이지 캐시와 유사한 효과 + 확실성**

→ O_DIRECT든 뭐든 상관없이 확실하게 RAM에서 읽게 만드는 방법

#### C. GDS 비활성화 (vLLM/TGI 등이 O_DIRECT를 쓴다면)
```bash
export CUFILE_ENV_FORCE_COMPAT_MODE=1   # GDS 비활성(페이지 캐시 사용)
```

#### D. vmtouch로 강제 적재/고정
```bash
sudo apt-get install -y vmtouch
vmtouch -t /path/to/model.bin         # 페이지 캐시에 적재(touch)
vmtouch -l /path/to/model.bin         # 잠금(lock)으로 축출 방지
```
(운영에선 잠금은 신중히)

#### E. 컨테이너/메모리 제한 해제
Docker/Podman/K8s에서 메모리 제한이 걸려 있으면 늘리거나 해제

### HDD에서 읽는 경우 주의
- HDD는 첫 로딩이 느림 (예: 60GB ≈ 몇 분)
- 하지만 한 번 읽으면 캐시에 남아 두 번째부터는 RAM 속도
- 단, **GDS/O_DIRECT 경로면 이 이득이 없음** → tmpfs 복사 방식 사용

---

## ✅ vmtouch 방식 (LM Studio에서 테스트 완료)

**LM Studio는 O_DIRECT를 사용하지 않음** → vmtouch로 페이지 캐시 활용 가능!

### tmpfs vs vmtouch 비교

| | tmpfs (hdd_to_ramdisk.py) | vmtouch |
|---|---|---|
| **원리** | 파일을 RAM에 **복사** | 파일을 RAM **캐시에 적재** |
| **메모리** | used 증가 (점유) | buff/cache 증가 (빌림) |
| **확실성** | 100% RAM에서 읽음 | 메모리 압박 시 축출 가능 |
| **유연성** | 수동 관리 필요 | OS가 자동 관리 |
| **여러 모델** | RAM 나눠서 할당 | 여유 RAM 범위 내 자동 |

### vmtouch 사용법

```bash
# 설치
sudo apt install -y vmtouch

# 캐시 상태 확인
vmtouch /path/to/model.gguf

# 캐시에 적재 (복사 아님, 읽어서 캐시에 올림)
vmtouch -t /path/to/model.gguf

# 여러 모델 한번에 적재
vmtouch -t /mnt/data24tb/model/lmstudio/models/*/*/**.gguf

# 캐시 잠금 (축출 방지, 신중히 사용)
sudo vmtouch -l /path/to/model.gguf
```

### 실제 테스트 결과 (2025-01-23)

```bash
# 적재 전
free -h
# buff/cache: 32GB
vmtouch gpt-oss-120b-GGUF/*.gguf
# Resident Pages: 0.0001%

# 적재
vmtouch -t gpt-oss-120b-GGUF/*.gguf
# Touched Pages: 59GB, Elapsed: 225초 (약 4분)

# 적재 후
free -h
# buff/cache: 91GB (+59GB)
vmtouch gpt-oss-120b-GGUF/*.gguf
# Resident Pages: 100%

# LM Studio 로드 → 매우 빠름!
```

### 언제 어떤 방식을 쓸까?

| 상황 | 추천 방식 |
|------|----------|
| LM Studio 단독 사용 | **vmtouch** (간편) |
| O_DIRECT 쓰는 로더 (vLLM 등) | **tmpfs** (확실) |
| 메모리 여유 많음 + 여러 모델 | **vmtouch** (자동 관리) |
| 메모리 빡빡 + 확실한 성능 필요 | **tmpfs** (축출 방지) |

### 빠른 명령어 모음

```bash
# vmtouch: 모델 캐시 적재
vmtouch -t /mnt/data24tb/model/lmstudio/models/lmstudio-community/gpt-oss-120b-GGUF/*.gguf

# tmpfs: 모델 RAM 복사
sudo python3 ~/JOB_FOLD/LLM_test/LMStudio_JOB/hdd_to_ramdisk.py

# tmpfs 해제
sudo python3 ~/JOB_FOLD/LLM_test/LMStudio_JOB/hdd_to_ramdisk.py off
```

---

## 🎯 최종 결론: 이제 뭘 해야 하나?

### 현재 설정 상태

| 항목 | 상태 | 부팅 시 |
|------|------|---------|
| **inotify 설정** | ✅ 영구 설정됨 | 자동 적용 |
| **hdd_to_ramdisk.py** | 수동 스크립트 | 실행 안 됨 |
| **vmtouch** | 수동 도구 | 실행 안 됨 |

### 핵심: inotify 설정만으로 충분!

```
부팅 후 → inotify 자동 적용 → LM Studio 모델 로드 → 페이지 캐시 자동 적재!
         (영구 설정됨)                              (첫 로드 후 자동)
```

**결과:**
- 첫 번째 로드: HDD 속도 (느림)
- 두 번째 로드: RAM 캐시 속도 (빠름) ✅
- RAM 여유 있으면 여러 모델 자동 캐시 ✅

### hdd_to_ramdisk.py는 언제 필요한가?

| 상황 | hdd_to_ramdisk.py | vmtouch | 그냥 사용 |
|------|-------------------|---------|-----------|
| LM Studio 일반 사용 | ❌ 불필요 | ❌ 불필요 | ✅ 자동 캐시 |
| 첫 로드도 빠르게 | ✅ 미리 복사 | ✅ 미리 적재 | ❌ |
| vLLM 등 O_DIRECT 도구 | ✅ 필수 | ❌ 안 됨 | ❌ |
| 메모리 부족 환경 | ✅ 확실한 성능 | ❌ 축출 위험 | ❌ |

### 일반 사용자를 위한 요약

1. **inotify 영구 설정** (한 번만 하면 됨)
   ```bash
   sudo tee /etc/sysctl.d/99-inotify.conf << 'EOF'
   fs.inotify.max_user_watches = 524288
   fs.inotify.max_user_instances = 1024
   EOF
   ```

2. **그냥 LM Studio 사용** → 자동으로 캐시됨!

3. **첫 로드가 너무 느리면** → vmtouch로 미리 적재
   ```bash
   vmtouch -t /mnt/data24tb/model/lmstudio/models/*/*/**.gguf
   ```

---

## 🦙 Ollama에서도 페이지 캐시 작동

### Ollama vs LM Studio 비교

| 도구 | 페이지 캐시 | inotify 설정 필요 | 비고 |
|------|------------|------------------|------|
| **LM Studio** | ✅ 작동 | ✅ 필수 | inotify 없으면 캐시 안 됨 |
| **Ollama** | ✅ 작동 | ❌ 불필요 | llama.cpp 기반, 자동 작동 |
| **vLLM** | ❌ O_DIRECT | - | tmpfs 필수 |

### Ollama 특징
- **llama.cpp 기반** → O_DIRECT 사용 안 함
- **페이지 캐시 자동 작동** (별도 설정 불필요)
- 첫 로드만 느리고, 두 번째부터 자동으로 빠름

### Ollama 모델 경로
```bash
# 환경변수로 확인
echo $OLLAMA_MODELS
# 또는
cat /etc/systemd/system/ollama.service | grep OLLAMA_MODELS
# 예: /mnt/data24tb/model/ollama
```

### Ollama 캐시 상태 확인
```bash
# 캐시 상태 확인
sudo vmtouch /mnt/data24tb/model/ollama/blobs/

# 미리 캐시에 적재 (선택)
sudo vmtouch -t /mnt/data24tb/model/ollama/blobs/
```

### Ollama 테스트 방법
```bash
# 1) 캐시 비우기
sudo sh -c 'echo 3 > /proc/sys/vm/drop_caches'

# 2) 첫 번째 로드 (느림)
time ollama run gpt-oss:20b "hi" --verbose

# 3) 두 번째 로드 (빠름)
time ollama run gpt-oss:20b "hi" --verbose

# 4) 캐시 확인
sudo vmtouch /mnt/data24tb/model/ollama/blobs/
```

### 결론
**Ollama는 그냥 쓰면 됩니다!** 별도 설정 없이 페이지 캐시가 자동 작동합니다.